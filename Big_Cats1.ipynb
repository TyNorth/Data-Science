{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TyroneNorth/Data-Science/blob/master/Big_Cats1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y73gTVmbh-j2"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Tyrone North\n",
        "Title: Image Recognition via Convolutional Neural Networks\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbLxfCW1BGZ7"
      },
      "source": [
        "#Motivation/Purpose\n",
        "\n",
        "Big Cats are some of the most endandered species on the planet. These ferocious predators numbers have been dwindling for decades and tracking them can be crucial to their survival if we do not wish they go extinct. This model will be trained to identify  7 of the big cats.\n",
        "\n",
        "\n",
        "Tools and Technologies:\n",
        "\n",
        "1. Tensorflow framework and tools for access to Keras and advanced tools\n",
        "2. Keras deep learning framework for designing and training a model\n",
        "3. Convolutional Neural Netowrks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e14IGv3mkcZR"
      },
      "source": [
        "#What are Covnets?\n",
        "Convolutional Neural Networks is a neural network architecture that starts with a convolutional layer with the goal of extracting common patterns from training instances. \n",
        "Several kernal filters are applied and convolve the raw pixel values into higher level patterns.\n",
        "Taking sections of the image equal to the size of the kernel and calculating the dot product between the values in the path and those in the kernel matrix\n",
        "The kernal is then slid across the entire image convolving the image as it goes\n",
        "The convolutional layer is followed by a non-linear activation function. The output is passed along to the pooling layer where the max or the avg of the convolved kernel. \n",
        "Big models include many pooling and convolutional layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S6LRmgdWmSef"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "import os, shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense, MaxPooling2D, Conv2D, Dropout \n",
        "from tensorflow.keras.optimizers import RMSprop \n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import callbacks\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5QPC_XsAuMS",
        "outputId": "21d8ac0c-72af-4357-ab6e-691296c231b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNeJbsc6mSej"
      },
      "outputs": [],
      "source": [
        "#create subfolders for training, testing, and val;idation sets\n",
        "\n",
        "\n",
        "original_dataset_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats'\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/Grad School/COSC 6300 -  Programming for Data Science/Final Project/Big Cats'\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train'\n",
        "\n",
        "validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation'\n",
        "\n",
        "test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/Grad School/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test'\n",
        "\n",
        "cheetah_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Cheetah'\n",
        "\n",
        "cheetah_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Cheetah'\n",
        "\n",
        "cheetah_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation/Cheetah'\n",
        "\n",
        "cougar_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Cougar'\n",
        "\n",
        "cougar_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Cougar'\n",
        "\n",
        "cougar_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Cougar'\n",
        "\n",
        "jaguar_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Jaguars'\n",
        "\n",
        "jaguar_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Jaguars'\n",
        "\n",
        "jaguar_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation/Jaguars'\n",
        "\n",
        "leopard_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Leopard'\n",
        "\n",
        "leopard_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Leopard'\n",
        "\n",
        "leopard_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Leopard'\n",
        "\n",
        "lions_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Lions'\n",
        "\n",
        "lions_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Lions'\n",
        "\n",
        "lions_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation/Lions'\n",
        "\n",
        "lynx_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Lynx'\n",
        "\n",
        "lynx_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Lynx'\n",
        "\n",
        "lynx_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation/Lynx'\n",
        "\n",
        "tigers_train_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Train/Tigers'\n",
        "\n",
        "tigers_test_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Test/Tigers'\n",
        "\n",
        "tigers_validation_dir = '/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/Validation/Tigers'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ev2CyO7mSel",
        "outputId": "374e50aa-4fda-4562-bc72-4a1f3d9e32e6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total training cheetah images: 627 \n",
            " total training cougar images: 358 \n",
            " total training jaguar images: 665 \n",
            " total training leopard images: 211 \n",
            " total training lions images: 210 \n",
            " total training lynx images: 790 \n",
            "\n",
            "total validation cheetah images: 98 \n",
            " total validation cougar images: 358 \n",
            " total validation jaguar images: 100 \n",
            " total validation leopard images: 211 \n",
            " total validation lions images: 23 \n",
            " total validation lynx images: 103 \n",
            "\n",
            "total test cheetah images: 270 \n",
            " total test cougar images: 195 \n",
            " total test jaguar images: 283 \n",
            " total test leopard images: 152 \n",
            " total test lions images: 99 \n",
            " total test lynx images: 378 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Number of images per training set\n",
        "\n",
        "print(f'total training cheetah images:', len(os.listdir(cheetah_train_dir)), '\\n',\n",
        "f'total training cougar images:', len(os.listdir(cougar_train_dir)), '\\n',\n",
        "f'total training jaguar images:', len(os.listdir(jaguar_train_dir)), '\\n',\n",
        "f'total training leopard images:', len(os.listdir(leopard_train_dir)), '\\n',\n",
        "f'total training lions images:', len(os.listdir(lions_train_dir)), '\\n',\n",
        "f'total training lynx images:', len(os.listdir(lynx_train_dir)), '\\n'\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "print(f'total validation cheetah images:', len(os.listdir(cheetah_validation_dir)), '\\n',\n",
        "f'total validation cougar images:', len(os.listdir(cougar_validation_dir)), '\\n',\n",
        "f'total validation jaguar images:', len(os.listdir(jaguar_validation_dir)), '\\n',\n",
        "f'total validation leopard images:', len(os.listdir(leopard_validation_dir)), '\\n',\n",
        "f'total validation lions images:', len(os.listdir(lions_validation_dir)), '\\n',\n",
        "f'total validation lynx images:', len(os.listdir(lynx_validation_dir)), '\\n'\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "print(f'total test cheetah images:', len(os.listdir(cheetah_test_dir)), '\\n',\n",
        "f'total test cougar images:', len(os.listdir(cougar_test_dir)), '\\n',\n",
        "f'total test jaguar images:', len(os.listdir(jaguar_test_dir)), '\\n',\n",
        "f'total test leopard images:', len(os.listdir(leopard_test_dir)), '\\n',\n",
        "f'total test lions images:', len(os.listdir(lions_test_dir)), '\\n',\n",
        "f'total test lynx images:', len(os.listdir(lynx_test_dir)), '\\n'\n",
        "      )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTu453F7gDba"
      },
      "source": [
        "#Defining the model blueprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2L12TLavVl5",
        "outputId": "3798a658-a010-431b-b79e-533c322d8be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 146, 146, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 73, 73, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 69, 69, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 34, 34, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 30, 30, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 12, 12, 64)        73792     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,138,311\n",
            "Trainable params: 1,138,311\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model blueprint, summary statistics, 1.1 million parameters\n",
        "\n",
        "model_blueprint = Sequential()\n",
        "\n",
        "model_blueprint.add(Conv2D(32,\n",
        "                  kernel_size = (3, 3),\n",
        "                  activation = 'relu', #rectified linear unit, zeroes out negative values\n",
        "                  input_shape = (150, 150, 3)))\n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model_blueprint.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  \n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model_blueprint.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model_blueprint.add(Flatten())\n",
        "model_blueprint.add(Dense(512, activation = 'relu'))\n",
        "model_blueprint.add(Dense(7, activation = 'softmax')) #Returns an array of 7 probability scores\n",
        "\n",
        "model_blueprint.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UShLdIrUmSeq",
        "outputId": "046cd6e7-7599-4df1-d1ab-aebc3011fd75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#defining convolutional neural network  \n",
        "\n",
        "RMS = RMSprop(lr=1e-4) #optimizer, updates the network with data based on optimizer and loss function\n",
        "\n",
        "def convolutional_model(model_name = str):\n",
        "  '''Defines a convolutional nueral network.\n",
        "  Takes model name and returns pre-configured network.'''\n",
        "  model_name = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "  model_name.add(Conv2D(32,\n",
        "                  kernel_size = (3, 3),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (150, 150, 3)))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  \n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  model_name.add(Flatten())\n",
        "  model_name.add(Dense(512, activation = 'relu'))\n",
        "  model_name.add(Dense(7, activation = 'softmax'))\n",
        "\n",
        "\n",
        "#loss function states how the network will be able to measure its performance\n",
        "  model_name.compile(optimizer = RMS, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrJR-L7ugMLW"
      },
      "source": [
        "#Image setup for training and testing data\n",
        "\n",
        "The keras preprocessing image module has built-in functionality for generating images into batches of preprocessed tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SFQeIFumSet",
        "outputId": "5e325dc5-0d6e-4347-fc4b-953880d9397e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3494 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "#rescales all images by 1/255\n",
        "\n",
        "def create_train_datagen():\n",
        "  '''Resizes images for training set.'''\n",
        "  train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "  return train_datagen\n",
        "\n",
        "train_datagen = create_train_datagen()\n",
        "\n",
        "def create_test_datagen():\n",
        "  '''Resizes images for test set.'''\n",
        "  test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "  return test_datagen\n",
        "\n",
        "test_datagen = create_test_datagen()\n",
        "\n",
        "\n",
        "#resizes all triaining images to 150 x 150\n",
        "def create_train_generator(batch_size = int, target_size = (int, int), class_mode =  'binary' ):\n",
        "  '''Creates image generator for feeding batches of images.'''\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = (150, 150),\n",
        "      batch_size = 20,\n",
        "      class_mode = 'categorical')\n",
        "  return train_generator\n",
        "\n",
        "train_generator = create_train_generator(batch_size = 20, target_size = (150,150))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhw0gUmjq0Uw",
        "outputId": "8ca7467b-81f2-43ac-f77c-616683568b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 672 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "#resizes all validation images to 150 x 150\n",
        "def create_validation_generator(batch_size = int, target_size = (int, int), class_mode = 'binary'):\n",
        "  '''Creates image generator for validation images.\n",
        "  Defines the batch size, resizes the image and sets class mode'''\n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size = (150, 150),\n",
        "      batch_size = 20,\n",
        "      class_mode = 'categorical')\n",
        "  return validation_generator\n",
        "\n",
        "validation_generator = create_validation_generator(20, (150,150))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3R3xP9zsZ2c",
        "outputId": "f84441bf-9f63-4f07-e7ee-2beaa71ba7b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data batch shape :  (20, 150, 150, 3) \n",
            " labels batch shape :  (20, 7)\n"
          ]
        }
      ],
      "source": [
        "#checking the shape of batches\n",
        "for data_batch, labels_batch in train_generator:\n",
        "  print('data batch shape : ', data_batch.shape, '\\n',\n",
        "        'labels batch shape : ', labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYDG_odlIWXl"
      },
      "outputs": [],
      "source": [
        "#Setting up early stopping to halt the training of the model once accuracy on validation set stops improving\n",
        "#This will help prevent severe overfitting and underfitting\n",
        "#from tensorflow.keras import callbacks\n",
        "\n",
        "\n",
        "es = callbacks.EarlyStopping(monitor = 'val_loss', restore_best_weights = True, mode = 'auto', verbose = 1, patience = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTPdSTm3N6DE"
      },
      "outputs": [],
      "source": [
        "#Model fit function\n",
        "def history(model = tf.keras.models.Sequential, steps_per_epoch = int, epochs = int, validation_steps = int): #takes model and three int parameters\n",
        "  '''Creates a network object.\n",
        "  Defines the training parameters and returns model.fit object.\n",
        "  Takes keras model, steps per epoch, epochs, and validation steps'''\n",
        "  history = model.fit(train_generator,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=validation_generator,\n",
        "                      validation_steps=validation_steps,\n",
        "                      callbacks = [es])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D16NhsL2gSym"
      },
      "source": [
        "##Training Model #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzJGh5dPx1sB",
        "outputId": "cf85c9f8-1f2a-4813-be07-6c84cf75222e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 87/100 [=========================>....] - ETA: 1:16 - loss: 1.8593 - accuracy: 0.2333"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 719s 7s/step - loss: 1.8478 - accuracy: 0.2470 - val_loss: 2.0631 - val_accuracy: 0.2175\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 423s 4s/step - loss: 1.6795 - accuracy: 0.3551 - val_loss: 1.8483 - val_accuracy: 0.2725\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 387s 4s/step - loss: 1.5625 - accuracy: 0.4125 - val_loss: 2.0077 - val_accuracy: 0.2700\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 378s 4s/step - loss: 1.5044 - accuracy: 0.4168 - val_loss: 1.7243 - val_accuracy: 0.3300\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 381s 4s/step - loss: 1.4817 - accuracy: 0.4383 - val_loss: 1.7587 - val_accuracy: 0.3250\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 377s 4s/step - loss: 1.4349 - accuracy: 0.4739 - val_loss: 1.6261 - val_accuracy: 0.3425\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 378s 4s/step - loss: 1.3466 - accuracy: 0.5025 - val_loss: 1.5824 - val_accuracy: 0.4075\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 378s 4s/step - loss: 1.2687 - accuracy: 0.5290 - val_loss: 1.4836 - val_accuracy: 0.4500\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 379s 4s/step - loss: 1.2015 - accuracy: 0.5527 - val_loss: 1.4088 - val_accuracy: 0.4350\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 380s 4s/step - loss: 1.1574 - accuracy: 0.5775 - val_loss: 1.4009 - val_accuracy: 0.4575\n",
            "Epoch 11/50\n",
            "  1/100 [..............................] - ETA: 6:11 - loss: 1.0081 - accuracy: 0.5500"
          ]
        }
      ],
      "source": [
        "#fitting/training the neural network\n",
        "\n",
        "model_one = convolutional_model('baseline_model')\n",
        "\n",
        "history1 = history(model_one, 100, 50, 20)#100 = steps per epoch, 50 = epochs, 20 = validation  steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnK3bM0LyaWt"
      },
      "outputs": [],
      "source": [
        "#save model for later use\n",
        "model_one.save('big_cats_pre_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ctkWuoiiEV"
      },
      "source": [
        "###Accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM8acOiA0PL0"
      },
      "outputs": [],
      "source": [
        "#Defining accuracy and loss graphs\n",
        "\n",
        "def acc_vloss(history_model = str, filename = str, filename2 = str):\n",
        "  '''Plots the training and validation accuracy and loss'''\n",
        "  acc = history_model.history['accuracy']\n",
        "  val_acc = history_model.history['val_accuracy']\n",
        "  loss = history_model.history['loss']\n",
        "  val_loss = history_model.history['val_loss']\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.savefig(filename2)\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(filename)\n",
        "  plt.show()\n",
        "  \n",
        "acc_vloss(history1, 'first_run_acc.svg', 'first_run_loss.svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjSJRRyXvZlH"
      },
      "source": [
        "The Training accuracy continues to increase as the chart shows. It is  reasonable to assume that the accuracy is likely to increase to 100% but thanks to early stopping the model never trained that far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D27rWYrZxJV9"
      },
      "source": [
        "Data Augmentation will help with the low image count. By transforming each image in the dataset either by rotating, or shifting, etc the image, we can essentially add variations of the imageset to increase the training image pool. This isn't new data, only remixed data seen from a different perspective. The data points will be higly correlated giving our model time training with feature sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb4_1wh9ykhC"
      },
      "source": [
        "I'll also include a dropout layer to help with the overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgctjEgi5vw"
      },
      "source": [
        "#Defining Second Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwI7qX0kzV79"
      },
      "outputs": [],
      "source": [
        "#model is overfitting badly\n",
        "#setting up data augmentation to mitigate overfitting on small dataset\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=40,\n",
        "                           width_shift_range=0.2,\n",
        "                           height_shift_range=0.2,\n",
        "                           shear_range=0.2,\n",
        "                           zoom_range=0.2,\n",
        "                           horizontal_flip=True,\n",
        "                           fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxzOIcPw0pGO"
      },
      "outputs": [],
      "source": [
        "#new convnet with dropout layer to mitigate overfitting\n",
        "\n",
        "def convolutional_dropout_model(model_name =str):\n",
        "  '''Defiines a CNN with dropout layer and returns network'''\n",
        "  model_name = Sequential()\n",
        "\n",
        "  model_name.add(Conv2D(32,\n",
        "                  kernel_size = (3, 3),\n",
        "                  activation = 'relu',\n",
        "                  input_shape = (150, 150, 3)))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  \n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
        "  model_name.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "  model_name.add(Flatten())\n",
        "  #Dropout rate is the fraction of the features that are zeroed out *note different implementation during test v training\n",
        "  model_name.add(Dropout(0.5)) \n",
        "  model_name.add(Dense(512, activation = 'relu'))\n",
        "  model_name.add(Dense(7, activation = 'softmax'))\n",
        "\n",
        "  model_name.compile(optimizer = RMS, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fp_N5VT1ABK"
      },
      "outputs": [],
      "source": [
        "#Generating augmented images\n",
        "\n",
        "def create_train_datagen_aug():\n",
        "  '''Augments training images.\n",
        "  Resizes, rotates, shifts dimensions, shear, zoom, and flips images.'''\n",
        "  train_datagen_aug = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,)\n",
        "  return train_datagen_aug\n",
        "\n",
        "train_datagen_aug = create_train_datagen_aug()\n",
        "\n",
        "test_gen =create_test_datagen()\n",
        "\n",
        "train_generator = create_train_generator(32, (150, 150))\n",
        "\n",
        "validation_generator = create_validation_generator((150,150), 32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lViVn-Fi17q"
      },
      "source": [
        "##Training** Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKxwMAl35P-q"
      },
      "outputs": [],
      "source": [
        "model_two = convolutional_dropout_model('dropout_model')\n",
        "model_two.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwEEaU-GENDU"
      },
      "outputs": [],
      "source": [
        "#training/fitting neural network with dropout layer\n",
        "\n",
        "\n",
        "history2 = history(model_two, 100, 100, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y35JcDFNEowN"
      },
      "outputs": [],
      "source": [
        "#saving second model\n",
        "model_two.save('second_run_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeCg5tPXjBUY"
      },
      "source": [
        "###Accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VILpRYMbDlhY"
      },
      "outputs": [],
      "source": [
        "#plot accuracy and loss\n",
        "acc_vloss(history2, 'second_run_acc.svg', 'second_run_loss.svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eie4QpJazL0q"
      },
      "source": [
        "#Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RZwAjnpzLcp"
      },
      "outputs": [],
      "source": [
        "#evaluating the final model\n",
        "def create_test_generator(batch_size = int, target_size = (int, int), class_mode = 'binary'):\n",
        "  '''Creates test image generator.\n",
        "  Takes batch size, target image size, and class mode.'''\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "  test_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=20,\n",
        "  class_mode='categorical')\n",
        "  return test_generator\n",
        "  \n",
        "test_loss, test_accuracy = model_two.evaluate(create_test_generator(20, (150, 150), 'categorical'), steps = 50)\n",
        "print('test acc:', test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdb8fakCjElV"
      },
      "source": [
        "#Loading Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDvvg4zodcTl"
      },
      "outputs": [],
      "source": [
        "#Using a pretrained model\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "#instantiating VGG16 convolutional base with 14.7 mil parameters\n",
        "\n",
        "convolutional_base = VGG16(weights = 'imagenet',\n",
        "                            include_top = False,\n",
        "                            input_shape = (150, 150, 3))\n",
        "\n",
        "convolutional_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIH7sgzUD_V4"
      },
      "source": [
        "##Using a pretrained model with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5FRfAkQpN1w"
      },
      "outputs": [],
      "source": [
        "\n",
        "#This method is slower and more expensive but allows data augmentation during training, which is great for smaller datasets\n",
        "#Adding convolutional base and Dense layers\n",
        "\n",
        "def convolutional_base_dense_model(model_name = str):\n",
        "  '''Defines base of network from pretrained model and freezes base'''\n",
        "  model_name = Sequential()\n",
        "\n",
        "  model_name.add(convolutional_base)\n",
        "  model_name.add(Flatten())\n",
        "  model_name.add(Dense(256, activation = 'relu'))\n",
        "  model_name.add(Dense(7, activation = 'softmax'))\n",
        "  return model_name\n",
        "\n",
        "#Freezing convolutional_base trainable parameters  \n",
        "convolutional_base.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp_ew9kRwNU7"
      },
      "outputs": [],
      "source": [
        "train_datagen_aug = create_train_datagen_aug()\n",
        "\n",
        "test_datagen = create_test_datagen()\n",
        "\n",
        "train_generator = create_train_generator(20, (150, 150), 'categorical')\n",
        "\n",
        "validation_generator = create_validation_generator(20, (150, 150), 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mczz0AzmwEwU"
      },
      "outputs": [],
      "source": [
        "model_four = convolutional_base_dense_model('trained_plus')\n",
        "\n",
        "model_four.compile(optimizer = RMS,\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX46WvB2jN2u"
      },
      "source": [
        "###Training Model 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k726_NhMok0"
      },
      "outputs": [],
      "source": [
        "def history(model = tf.keras.models.Sequential, steps_per_epoch = int, epochs = int, validation_steps = int): #takes model and three int parameters\n",
        "  '''Creates a network object.\n",
        "  Defines the training parameters and returns model.fit object.\n",
        "  Takes keras model, steps per epoch, epochs, and validation steps'''\n",
        "  history = model.fit(train_generator,\n",
        "                      steps_per_epoch=steps_per_epoch,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=validation_generator,\n",
        "                      validation_steps=validation_steps,\n",
        "                      callbacks = [callbacks.EarlyStopping(monitor = 'loss' )])\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n4P7w12t2TQ"
      },
      "outputs": [],
      "source": [
        "history4 = history(model_four, 100, 30, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDviqBi-C2aK"
      },
      "outputs": [],
      "source": [
        "model_four.save('contents/MyDrive/Documents/Grad School/Cosc 6300 - Programming for Data Science/Final Project/big_cats_four4.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5uLQ36MEM8N"
      },
      "source": [
        "#Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dIuqT7yDKmM"
      },
      "outputs": [],
      "source": [
        "#unfreezing some layers\n",
        "convolutional_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_DgNpgwk4kw"
      },
      "source": [
        "##Unfreezing model base for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "528qQJAiMhHk"
      },
      "outputs": [],
      "source": [
        "#unfreezing block5_pool & block5_conv1 - 3\n",
        "convolutional_base.trainable = True\n",
        "\n",
        "set_trainable = False \n",
        "\n",
        "for layer in convolutional_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "\n",
        "len(convolutional_base.trainable_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVOWMnn9k-Mj"
      },
      "source": [
        "##Training Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THkM7q4Beyue"
      },
      "outputs": [],
      "source": [
        "RMS = RMSprop(lr=1e-5)\n",
        "model_four.compile(loss = 'categorical_crossentropy', optimizer = RMS, metrics = ['accuracy'] )\n",
        "\n",
        "history5 = history(model_four, 100, 100, 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX77ksPLlFPC"
      },
      "source": [
        "###Accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fGwkE6IEgn-"
      },
      "outputs": [],
      "source": [
        "acc_vloss(history5, 'final_run_acc.svg', 'final_run_loss.svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHzT_uwslK4h"
      },
      "source": [
        "###Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp03eAe9hxCw"
      },
      "outputs": [],
      "source": [
        "#evaluating the final model\n",
        "def create_test_generator(batch_size = int, target_size = (int, int), class_mode = 'binary'):\n",
        "  '''Creates test image generator.\n",
        "  Takes batch size, target image size, and class mode.'''\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "  test_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=20,\n",
        "  class_mode='categorical')\n",
        "  return test_generator\n",
        "  \n",
        "test_loss, test_accuracy = model_four.evaluate(create_test_generator(20, (150, 150), 'categorical'), steps = 50)\n",
        "print('test acc:', test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voZPo_NZlA7H"
      },
      "outputs": [],
      "source": [
        "model_four.save('big_cat_final_model5.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prod_model = tf.keras.models.load_model('/content/drive/MyDrive/Documents/Grad School/MS Computer Science/COSC 6300 -  Programming for Data Science/Final Project/Big Cats/big_cats_pre_model.h5')"
      ],
      "metadata": {
        "id": "I74u2710Aky-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lkMooO1ipnwM"
      },
      "outputs": [],
      "source": [
        "class_names = ['cheetah', 'cougar', 'jaguar', 'leopard', 'lions', 'lynx', 'tiger']\n",
        "def predict_input_image(img):\n",
        "  img_4d=img.reshape(-1,150,150,3)\n",
        "  prediction=prod_model.predict(img_4d)[0]\n",
        "  return {class_names[i]: float(prediction[i]) for i in range(5)}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment"
      ],
      "metadata": {
        "id": "yESsCtjFCU_Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1LNNUMSf2dx"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nHqQOamVpFU5"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn2u6CnMBpAS",
        "outputId": "92d33aa3-98c1-49da-d00c-9e5c11be61cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vbDtEl9fpMcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f98ef1d-a905-435b-f85c-107a3b44bc24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        }
      ],
      "source": [
        "image = gr.inputs.Image(shape=(150,150))\n",
        "label = gr.outputs.Label(num_top_classes=len(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6LTQQ1bpcaT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "outputId": "44701716-5027-49bf-d3d8-8b3a36745024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://17701.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://17701.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "With very little data we can still train somewhat competent models by fine-tuning hyperparameters. Futurgermore, we saw how larger models with millions more parameters are mucgh more effective when train on a large dataset."
      ],
      "metadata": {
        "id": "7ruGQFTNCgLY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Big Cats1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}